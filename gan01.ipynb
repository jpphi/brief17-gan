{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Aj9P1qou7FYz2c3OHkK-Cg7-OOJDipzL",
      "authorship_tag": "ABX9TyOFUQJroGWK1o8RIyjcmxhs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpphi/brief17-gan/blob/master/gan01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9sMExTNwumH"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import os\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.preprocessing import image \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "latent_dim = 32 #32\n",
        "height = 32 #32\n",
        "width = 32 #32\n",
        "channels = 3 #3\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18z5ugmmZb25"
      },
      "source": [
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8aWWLzWb7oV"
      },
      "source": [
        "Générateur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKIJhmQXbtRG",
        "outputId": "b3af8770-9fcc-40c2-e336-ebbe2d81175a"
      },
      "source": [
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "\n",
        "# Transforms the input into a 16 × 16 128-channel feature map\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x= layers.Conv2D(256, 5, padding='same')(x)\n",
        "x= layers.LeakyReLU()(x)\n",
        "x= layers.Conv2D(256, 5, padding='same')(x)\n",
        "x= layers.LeakyReLU()(x)\n",
        "\n",
        "#Upsamples to 32 × 32\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN1ITOavcHDy"
      },
      "source": [
        "Discrinateur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNgz6nM3cIgo",
        "outputId": "7441b835-64b7-43ee-980e-372d57f193c5"
      },
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "\n",
        "\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "x = layers.Dropout(0.4)(x) #One dropout layer: an important trick!\n",
        "x = layers.Dense(1, activation='sigmoid')(x) # Classification layer\n",
        "\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(\n",
        "    lr=0.0008,\n",
        "    clipvalue=1.0,\n",
        "    decay=1e-8)\n",
        "\n",
        "discriminator.compile(optimizer=discriminator_optimizer,\n",
        "loss='binary_crossentropy')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmEhfcvucdW6"
      },
      "source": [
        "Le réseaux"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCJKyiwocU8D"
      },
      "source": [
        "# Sets discriminator weights to non-trainable (this will only apply to the gan model)\n",
        "\n",
        "discriminator.trainable = False \n",
        "\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4jEGJEVchZm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEFCeD2m3zRc",
        "outputId": "ccd01964-7aed-4378-9437-33d825c93603"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lFbY0Xi4zc3"
      },
      "source": [
        "#!ls \"drive/MyDrive/Colab Notebooks/b17datas/images/\" -all\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTS_GASkBaX9"
      },
      "source": [
        "#!rmdir \"drive/MyDrive/Colab Notebooks/b17datas/images/.ipynb_checkpoints\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDWIqcQPzVnC",
        "outputId": "1cec775f-635b-4e3c-9488-33affd6c6c7b"
      },
      "source": [
        "dataset = keras.preprocessing.image_dataset_from_directory(\n",
        "    \"drive/MyDrive/Colab Notebooks/b17datas/images/\", label_mode=None, image_size=(32, 32), batch_size=32\n",
        ")\n",
        "\n",
        "# -----> Pourquoi cette ligne ?\n",
        "dataset = dataset.map(lambda x: x / 255.0)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 files belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-XHdT4s3mNd"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWXmF_AVcb_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "062ce760-f6fc-4346-adcf-4e604938d909"
      },
      "source": [
        "x_train = np.empty(shape=(0,height, width, 3))\n",
        "\n",
        "for elt in dataset.as_numpy_iterator():\n",
        "    x_train = np.concatenate((x_train, elt), axis=0)\n",
        "      \n",
        "\n",
        "print(x_train.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XBRuzTBCQDe"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbQE4W6ECqCe"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeOUqL1QCq4P",
        "outputId": "f047b479-96b9-4bee-b56d-6dabfc92d439"
      },
      "source": [
        "iterations = 10000\n",
        "batch_size = 20\n",
        "save_dir = \"drive/MyDrive/Colab Notebooks/b17datas/sav_dir\" # Specifies where you want to save generated images\n",
        "\n",
        "start = 0\n",
        "t_d_loss=[]\n",
        "t_a_loss=[]\n",
        "for step in range(iterations):\n",
        "    # Samples random points in the latent space\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
        "\n",
        "    generated_images = generator.predict(random_latent_vectors) # Decodes them to fake images\n",
        "\n",
        "    # 3 lignes suivantes: Combines them with real images\n",
        "    stop = start + batch_size\n",
        "    real_images = x_train[start: stop]\n",
        "    combined_images = np.concatenate([generated_images, real_images]) # Assembles labels, discriminating real from fake images\n",
        "\n",
        "\n",
        "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
        "    np.zeros((batch_size, 1))])\n",
        "    labels += 0.05 * np.random.random(labels.shape) # Adds random noise to the labels—an important trick!\n",
        "\n",
        "\n",
        "    d_loss = discriminator.train_on_batch(combined_images, labels) # Trains the discriminator\n",
        "\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim)) # Samples random points in the latent space\n",
        "\n",
        "    misleading_targets = np.zeros((batch_size, 1)) # Assembles labels that say “these are all real images” (it’s a lie!)\n",
        "\n",
        "    # Trains the generator (via the gan model, where the discriminator weights are frozen)\n",
        "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "\n",
        "    start += batch_size\n",
        "    if start > len(x_train) - batch_size:\n",
        "        start = 0\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(step)\n",
        "\n",
        "        gan.save_weights('drive/MyDrive/Colab Notebooks/b17datas/gan.h5') # Occasionally saves and plots (every 100 steps)\n",
        "        discriminator.save_weights('drive/MyDrive/Colab Notebooks/b17datas/dis.h5') # Occasionally saves and plots (every 100 steps)\n",
        "        generator.save_weights(\"drive/MyDrive/Colab Notebooks/b17datas/gen.h5\")\n",
        "        # Prints metrics\n",
        "        print('discriminator loss:', d_loss)\n",
        "        print('adversarial loss:', a_loss)\n",
        "        t_d_loss.append(d_loss)\n",
        "        t_a_loss.append(a_loss)\n",
        "\n",
        "        # Saves one generated image\n",
        "        img = image.array_to_img(generated_images[0] * 255., scale=False) \n",
        "        img.save(os.path.join(save_dir,'generated_' + str(step) + '.png'))\n",
        "\n",
        "        # Saves one real image for comparison\n",
        "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "        img.save(os.path.join(save_dir,'real_' + str(step) + '.png'))\n",
        "\n",
        "\n",
        "gan.save_weights('drive/MyDrive/Colab Notebooks/b17datas/ganfinal.h5') # Occasionally saves and plots (every 100 steps)\n",
        "discriminator.save_weights('drive/MyDrive/Colab Notebooks/b17datas/disfinal.h5') # Occasionally saves and plots (every 100 steps)\n",
        "generator.save_weights(\"drive/MyDrive/Colab Notebooks/b17datas/genfinal.h5\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "discriminator loss: 0.6797264814376831\n",
            "adversarial loss: 0.6932629346847534\n",
            "100\n",
            "discriminator loss: 0.41326555609703064\n",
            "adversarial loss: 0.9736305475234985\n",
            "200\n",
            "discriminator loss: 0.7909333109855652\n",
            "adversarial loss: 1.4096368551254272\n",
            "300\n",
            "discriminator loss: 0.6478759050369263\n",
            "adversarial loss: 1.6160500049591064\n",
            "400\n",
            "discriminator loss: 0.5789340138435364\n",
            "adversarial loss: 0.8934712409973145\n",
            "500\n",
            "discriminator loss: 0.4881327748298645\n",
            "adversarial loss: 1.2047773599624634\n",
            "600\n",
            "discriminator loss: 0.5965704321861267\n",
            "adversarial loss: 0.9070173501968384\n",
            "700\n",
            "discriminator loss: 0.7528828382492065\n",
            "adversarial loss: 0.8704701662063599\n",
            "800\n",
            "discriminator loss: 0.6807634830474854\n",
            "adversarial loss: 0.8594907522201538\n",
            "900\n",
            "discriminator loss: 0.4622802734375\n",
            "adversarial loss: 1.5640817880630493\n",
            "1000\n",
            "discriminator loss: 0.7398364543914795\n",
            "adversarial loss: 2.4664077758789062\n",
            "1100\n",
            "discriminator loss: 0.22570376098155975\n",
            "adversarial loss: 2.468961715698242\n",
            "1200\n",
            "discriminator loss: 0.5215751528739929\n",
            "adversarial loss: 0.7468041181564331\n",
            "1300\n",
            "discriminator loss: 0.681228756904602\n",
            "adversarial loss: 0.9225319027900696\n",
            "1400\n",
            "discriminator loss: 0.6457259058952332\n",
            "adversarial loss: 2.3765952587127686\n",
            "1500\n",
            "discriminator loss: 0.3791242241859436\n",
            "adversarial loss: 2.9269745349884033\n",
            "1600\n",
            "discriminator loss: 0.3214273452758789\n",
            "adversarial loss: 2.0512619018554688\n",
            "1700\n",
            "discriminator loss: 0.33590108156204224\n",
            "adversarial loss: 1.5549662113189697\n",
            "1800\n",
            "discriminator loss: 0.6641993522644043\n",
            "adversarial loss: 1.0486828088760376\n",
            "1900\n",
            "discriminator loss: 0.3907829523086548\n",
            "adversarial loss: 2.6588528156280518\n",
            "2000\n",
            "discriminator loss: 0.3555263876914978\n",
            "adversarial loss: 3.191718816757202\n",
            "2100\n",
            "discriminator loss: 0.436897337436676\n",
            "adversarial loss: 1.367031455039978\n",
            "2200\n",
            "discriminator loss: 0.29539498686790466\n",
            "adversarial loss: 1.6138092279434204\n",
            "2300\n",
            "discriminator loss: 0.32942402362823486\n",
            "adversarial loss: 1.4387331008911133\n",
            "2400\n",
            "discriminator loss: 0.2508052885532379\n",
            "adversarial loss: 4.963555335998535\n",
            "2500\n",
            "discriminator loss: 0.40690016746520996\n",
            "adversarial loss: 1.492643117904663\n",
            "2600\n",
            "discriminator loss: 0.17626070976257324\n",
            "adversarial loss: 3.093632459640503\n",
            "2700\n",
            "discriminator loss: 0.4223727583885193\n",
            "adversarial loss: 3.723219394683838\n",
            "2800\n",
            "discriminator loss: 0.4190394878387451\n",
            "adversarial loss: 2.2518787384033203\n",
            "2900\n",
            "discriminator loss: 0.13384613394737244\n",
            "adversarial loss: 3.6473422050476074\n",
            "3000\n",
            "discriminator loss: 0.34896165132522583\n",
            "adversarial loss: 1.8345714807510376\n",
            "3100\n",
            "discriminator loss: 0.6467664241790771\n",
            "adversarial loss: 6.001378536224365\n",
            "3200\n",
            "discriminator loss: 0.3668419420719147\n",
            "adversarial loss: 4.752226829528809\n",
            "3300\n",
            "discriminator loss: 0.3135107457637787\n",
            "adversarial loss: 4.958077907562256\n",
            "3400\n",
            "discriminator loss: 0.3611665368080139\n",
            "adversarial loss: 1.5667216777801514\n",
            "3500\n",
            "discriminator loss: 0.3574705719947815\n",
            "adversarial loss: 6.189414978027344\n",
            "3600\n",
            "discriminator loss: 0.13696825504302979\n",
            "adversarial loss: 3.9746017456054688\n",
            "3700\n",
            "discriminator loss: 0.34479355812072754\n",
            "adversarial loss: 2.2305734157562256\n",
            "3800\n",
            "discriminator loss: 0.858487606048584\n",
            "adversarial loss: 2.5338826179504395\n",
            "3900\n",
            "discriminator loss: 0.19107452034950256\n",
            "adversarial loss: 3.1924521923065186\n",
            "4000\n",
            "discriminator loss: 0.18261674046516418\n",
            "adversarial loss: 3.856595993041992\n",
            "4100\n",
            "discriminator loss: 0.20692849159240723\n",
            "adversarial loss: 2.9997382164001465\n",
            "4200\n",
            "discriminator loss: 0.260498970746994\n",
            "adversarial loss: 2.297456741333008\n",
            "4300\n",
            "discriminator loss: 0.1865648478269577\n",
            "adversarial loss: 1.9938617944717407\n",
            "4400\n",
            "discriminator loss: 0.18551374971866608\n",
            "adversarial loss: 3.0867724418640137\n",
            "4500\n",
            "discriminator loss: 0.19293050467967987\n",
            "adversarial loss: 2.8261878490448\n",
            "4600\n",
            "discriminator loss: 0.19786573946475983\n",
            "adversarial loss: 2.6094582080841064\n",
            "4700\n",
            "discriminator loss: 0.3499864637851715\n",
            "adversarial loss: 4.7437872886657715\n",
            "4800\n",
            "discriminator loss: 0.16270704567432404\n",
            "adversarial loss: 2.889787197113037\n",
            "4900\n",
            "discriminator loss: 0.1572498381137848\n",
            "adversarial loss: 2.663710832595825\n",
            "5000\n",
            "discriminator loss: 0.269096702337265\n",
            "adversarial loss: 3.3459346294403076\n",
            "5100\n",
            "discriminator loss: 0.2531937062740326\n",
            "adversarial loss: 2.5209412574768066\n",
            "5200\n",
            "discriminator loss: 0.29498091340065\n",
            "adversarial loss: 2.7817978858947754\n",
            "5300\n",
            "discriminator loss: 0.5042420625686646\n",
            "adversarial loss: 1.99717116355896\n",
            "5400\n",
            "discriminator loss: 0.647927463054657\n",
            "adversarial loss: 5.546294212341309\n",
            "5500\n",
            "discriminator loss: 0.36160141229629517\n",
            "adversarial loss: 2.222670078277588\n",
            "5600\n",
            "discriminator loss: 0.1609121561050415\n",
            "adversarial loss: 3.2681820392608643\n",
            "5700\n",
            "discriminator loss: 0.11352197825908661\n",
            "adversarial loss: 3.339707851409912\n",
            "5800\n",
            "discriminator loss: 0.22436818480491638\n",
            "adversarial loss: 2.972954750061035\n",
            "5900\n",
            "discriminator loss: 0.13229058682918549\n",
            "adversarial loss: 4.666874885559082\n",
            "6000\n",
            "discriminator loss: 0.6614745259284973\n",
            "adversarial loss: 2.246936321258545\n",
            "6100\n",
            "discriminator loss: 0.15845194458961487\n",
            "adversarial loss: 4.461391448974609\n",
            "6200\n",
            "discriminator loss: 0.39499369263648987\n",
            "adversarial loss: 2.9208550453186035\n",
            "6300\n",
            "discriminator loss: 0.1629820317029953\n",
            "adversarial loss: 5.712162017822266\n",
            "6400\n",
            "discriminator loss: 0.11781581491231918\n",
            "adversarial loss: 9.033801078796387\n",
            "6500\n",
            "discriminator loss: 0.30192631483078003\n",
            "adversarial loss: 2.9895544052124023\n",
            "6600\n",
            "discriminator loss: 0.18840834498405457\n",
            "adversarial loss: 4.219736576080322\n",
            "6700\n",
            "discriminator loss: 0.34405460953712463\n",
            "adversarial loss: 2.8684659004211426\n",
            "6800\n",
            "discriminator loss: 0.2489434778690338\n",
            "adversarial loss: 1.6172701120376587\n",
            "6900\n",
            "discriminator loss: 0.13789324462413788\n",
            "adversarial loss: 6.909234523773193\n",
            "7000\n",
            "discriminator loss: 0.2651441693305969\n",
            "adversarial loss: 3.529264450073242\n",
            "7100\n",
            "discriminator loss: -0.03299202397465706\n",
            "adversarial loss: 7.0466718673706055\n",
            "7200\n",
            "discriminator loss: 0.1253373920917511\n",
            "adversarial loss: 4.552117347717285\n",
            "7300\n",
            "discriminator loss: 0.3180778920650482\n",
            "adversarial loss: 3.2430107593536377\n",
            "7400\n",
            "discriminator loss: 0.433417946100235\n",
            "adversarial loss: 8.382827758789062\n",
            "7500\n",
            "discriminator loss: 0.13119354844093323\n",
            "adversarial loss: 3.2389450073242188\n",
            "7600\n",
            "discriminator loss: 0.18762466311454773\n",
            "adversarial loss: 8.178586959838867\n",
            "7700\n",
            "discriminator loss: 0.08090855926275253\n",
            "adversarial loss: 4.426478862762451\n",
            "7800\n",
            "discriminator loss: 0.3463805019855499\n",
            "adversarial loss: 2.267897367477417\n",
            "7900\n",
            "discriminator loss: 0.2968960702419281\n",
            "adversarial loss: 3.470844268798828\n",
            "8000\n",
            "discriminator loss: 0.12413865327835083\n",
            "adversarial loss: 10.033247947692871\n",
            "8100\n",
            "discriminator loss: 0.2810409963130951\n",
            "adversarial loss: 2.477616786956787\n",
            "8200\n",
            "discriminator loss: -0.021257638931274414\n",
            "adversarial loss: 9.419225692749023\n",
            "8300\n",
            "discriminator loss: 0.40077051520347595\n",
            "adversarial loss: 3.1524529457092285\n",
            "8400\n",
            "discriminator loss: 0.0825478583574295\n",
            "adversarial loss: 5.308005332946777\n",
            "8500\n",
            "discriminator loss: 0.756016731262207\n",
            "adversarial loss: 2.1838057041168213\n",
            "8600\n",
            "discriminator loss: 0.24632711708545685\n",
            "adversarial loss: 5.428800106048584\n",
            "8700\n",
            "discriminator loss: 0.06611241400241852\n",
            "adversarial loss: 5.56175422668457\n",
            "8800\n",
            "discriminator loss: 0.3416644334793091\n",
            "adversarial loss: 3.7005794048309326\n",
            "8900\n",
            "discriminator loss: 0.6631962656974792\n",
            "adversarial loss: 11.297475814819336\n",
            "9000\n",
            "discriminator loss: -0.010389420203864574\n",
            "adversarial loss: 9.371066093444824\n",
            "9100\n",
            "discriminator loss: 0.2124135047197342\n",
            "adversarial loss: 13.023420333862305\n",
            "9200\n",
            "discriminator loss: 0.09494663774967194\n",
            "adversarial loss: 7.4517083168029785\n",
            "9300\n",
            "discriminator loss: 0.1489478051662445\n",
            "adversarial loss: 7.088723182678223\n",
            "9400\n",
            "discriminator loss: 0.17955739796161652\n",
            "adversarial loss: 5.678095817565918\n",
            "9500\n",
            "discriminator loss: 0.03257729858160019\n",
            "adversarial loss: 10.117956161499023\n",
            "9600\n",
            "discriminator loss: 0.1519242227077484\n",
            "adversarial loss: 4.781850814819336\n",
            "9700\n",
            "discriminator loss: 0.08278144896030426\n",
            "adversarial loss: 12.246844291687012\n",
            "9800\n",
            "discriminator loss: 0.0029369040858000517\n",
            "adversarial loss: 6.0775580406188965\n",
            "9900\n",
            "discriminator loss: 0.23556232452392578\n",
            "adversarial loss: 8.723676681518555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWVnoJIHCq-y",
        "outputId": "e1665d60-1553-4712-f827-9e476f617093"
      },
      "source": [
        "t_a_loss"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6932629346847534,\n",
              " 0.9736305475234985,\n",
              " 1.4096368551254272,\n",
              " 1.6160500049591064,\n",
              " 0.8934712409973145,\n",
              " 1.2047773599624634,\n",
              " 0.9070173501968384,\n",
              " 0.8704701662063599,\n",
              " 0.8594907522201538,\n",
              " 1.5640817880630493,\n",
              " 2.4664077758789062,\n",
              " 2.468961715698242,\n",
              " 0.7468041181564331,\n",
              " 0.9225319027900696,\n",
              " 2.3765952587127686,\n",
              " 2.9269745349884033,\n",
              " 2.0512619018554688,\n",
              " 1.5549662113189697,\n",
              " 1.0486828088760376,\n",
              " 2.6588528156280518,\n",
              " 3.191718816757202,\n",
              " 1.367031455039978,\n",
              " 1.6138092279434204,\n",
              " 1.4387331008911133,\n",
              " 4.963555335998535,\n",
              " 1.492643117904663,\n",
              " 3.093632459640503,\n",
              " 3.723219394683838,\n",
              " 2.2518787384033203,\n",
              " 3.6473422050476074,\n",
              " 1.8345714807510376,\n",
              " 6.001378536224365,\n",
              " 4.752226829528809,\n",
              " 4.958077907562256,\n",
              " 1.5667216777801514,\n",
              " 6.189414978027344,\n",
              " 3.9746017456054688,\n",
              " 2.2305734157562256,\n",
              " 2.5338826179504395,\n",
              " 3.1924521923065186,\n",
              " 3.856595993041992,\n",
              " 2.9997382164001465,\n",
              " 2.297456741333008,\n",
              " 1.9938617944717407,\n",
              " 3.0867724418640137,\n",
              " 2.8261878490448,\n",
              " 2.6094582080841064,\n",
              " 4.7437872886657715,\n",
              " 2.889787197113037,\n",
              " 2.663710832595825,\n",
              " 3.3459346294403076,\n",
              " 2.5209412574768066,\n",
              " 2.7817978858947754,\n",
              " 1.99717116355896,\n",
              " 5.546294212341309,\n",
              " 2.222670078277588,\n",
              " 3.2681820392608643,\n",
              " 3.339707851409912,\n",
              " 2.972954750061035,\n",
              " 4.666874885559082,\n",
              " 2.246936321258545,\n",
              " 4.461391448974609,\n",
              " 2.9208550453186035,\n",
              " 5.712162017822266,\n",
              " 9.033801078796387,\n",
              " 2.9895544052124023,\n",
              " 4.219736576080322,\n",
              " 2.8684659004211426,\n",
              " 1.6172701120376587,\n",
              " 6.909234523773193,\n",
              " 3.529264450073242,\n",
              " 7.0466718673706055,\n",
              " 4.552117347717285,\n",
              " 3.2430107593536377,\n",
              " 8.382827758789062,\n",
              " 3.2389450073242188,\n",
              " 8.178586959838867,\n",
              " 4.426478862762451,\n",
              " 2.267897367477417,\n",
              " 3.470844268798828,\n",
              " 10.033247947692871,\n",
              " 2.477616786956787,\n",
              " 9.419225692749023,\n",
              " 3.1524529457092285,\n",
              " 5.308005332946777,\n",
              " 2.1838057041168213,\n",
              " 5.428800106048584,\n",
              " 5.56175422668457,\n",
              " 3.7005794048309326,\n",
              " 11.297475814819336,\n",
              " 9.371066093444824,\n",
              " 13.023420333862305,\n",
              " 7.4517083168029785,\n",
              " 7.088723182678223,\n",
              " 5.678095817565918,\n",
              " 10.117956161499023,\n",
              " 4.781850814819336,\n",
              " 12.246844291687012,\n",
              " 6.0775580406188965,\n",
              " 8.723676681518555]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geulMYHlBBFF",
        "outputId": "65b4405b-26f6-42ed-9c18-4635f6d5c8d8"
      },
      "source": [
        "t_d_loss"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6797264814376831,\n",
              " 0.41326555609703064,\n",
              " 0.7909333109855652,\n",
              " 0.6478759050369263,\n",
              " 0.5789340138435364,\n",
              " 0.4881327748298645,\n",
              " 0.5965704321861267,\n",
              " 0.7528828382492065,\n",
              " 0.6807634830474854,\n",
              " 0.4622802734375,\n",
              " 0.7398364543914795,\n",
              " 0.22570376098155975,\n",
              " 0.5215751528739929,\n",
              " 0.681228756904602,\n",
              " 0.6457259058952332,\n",
              " 0.3791242241859436,\n",
              " 0.3214273452758789,\n",
              " 0.33590108156204224,\n",
              " 0.6641993522644043,\n",
              " 0.3907829523086548,\n",
              " 0.3555263876914978,\n",
              " 0.436897337436676,\n",
              " 0.29539498686790466,\n",
              " 0.32942402362823486,\n",
              " 0.2508052885532379,\n",
              " 0.40690016746520996,\n",
              " 0.17626070976257324,\n",
              " 0.4223727583885193,\n",
              " 0.4190394878387451,\n",
              " 0.13384613394737244,\n",
              " 0.34896165132522583,\n",
              " 0.6467664241790771,\n",
              " 0.3668419420719147,\n",
              " 0.3135107457637787,\n",
              " 0.3611665368080139,\n",
              " 0.3574705719947815,\n",
              " 0.13696825504302979,\n",
              " 0.34479355812072754,\n",
              " 0.858487606048584,\n",
              " 0.19107452034950256,\n",
              " 0.18261674046516418,\n",
              " 0.20692849159240723,\n",
              " 0.260498970746994,\n",
              " 0.1865648478269577,\n",
              " 0.18551374971866608,\n",
              " 0.19293050467967987,\n",
              " 0.19786573946475983,\n",
              " 0.3499864637851715,\n",
              " 0.16270704567432404,\n",
              " 0.1572498381137848,\n",
              " 0.269096702337265,\n",
              " 0.2531937062740326,\n",
              " 0.29498091340065,\n",
              " 0.5042420625686646,\n",
              " 0.647927463054657,\n",
              " 0.36160141229629517,\n",
              " 0.1609121561050415,\n",
              " 0.11352197825908661,\n",
              " 0.22436818480491638,\n",
              " 0.13229058682918549,\n",
              " 0.6614745259284973,\n",
              " 0.15845194458961487,\n",
              " 0.39499369263648987,\n",
              " 0.1629820317029953,\n",
              " 0.11781581491231918,\n",
              " 0.30192631483078003,\n",
              " 0.18840834498405457,\n",
              " 0.34405460953712463,\n",
              " 0.2489434778690338,\n",
              " 0.13789324462413788,\n",
              " 0.2651441693305969,\n",
              " -0.03299202397465706,\n",
              " 0.1253373920917511,\n",
              " 0.3180778920650482,\n",
              " 0.433417946100235,\n",
              " 0.13119354844093323,\n",
              " 0.18762466311454773,\n",
              " 0.08090855926275253,\n",
              " 0.3463805019855499,\n",
              " 0.2968960702419281,\n",
              " 0.12413865327835083,\n",
              " 0.2810409963130951,\n",
              " -0.021257638931274414,\n",
              " 0.40077051520347595,\n",
              " 0.0825478583574295,\n",
              " 0.756016731262207,\n",
              " 0.24632711708545685,\n",
              " 0.06611241400241852,\n",
              " 0.3416644334793091,\n",
              " 0.6631962656974792,\n",
              " -0.010389420203864574,\n",
              " 0.2124135047197342,\n",
              " 0.09494663774967194,\n",
              " 0.1489478051662445,\n",
              " 0.17955739796161652,\n",
              " 0.03257729858160019,\n",
              " 0.1519242227077484,\n",
              " 0.08278144896030426,\n",
              " 0.0029369040858000517,\n",
              " 0.23556232452392578]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a2L44AgXn47"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}